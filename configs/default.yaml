# Default configuration for attention-based RL training
env_name: "CartPole-v1"
total_timesteps: 100000
eval_freq: 10000
n_eval_episodes: 10
save_freq: 50000
log_freq: 1000
seed: 42
device: "auto"
render: false
verbose: true

# PPO Hyperparameters
ppo:
  learning_rate: 3.0e-4
  gamma: 0.99
  gae_lambda: 0.95
  clip_ratio: 0.2
  value_loss_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  n_epochs: 4
  batch_size: 64

# Attention mechanism hyperparameters
attention:
  n_heads: 8
  d_model: 128
  n_layers: 2
  dropout: 0.1
  hidden_dim: 256

# Environment-specific settings
environments:
  CartPole-v1:
    max_episode_steps: 500
    reward_threshold: 475.0
  Acrobot-v1:
    max_episode_steps: 500
    reward_threshold: -100.0
  MountainCar-v0:
    max_episode_steps: 200
    reward_threshold: -110.0
